{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92as2SUq5N2Z",
        "outputId": "6793d0f9-443c-409d-c038-f1486b6b5ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-24 14:42:53--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-24 14:42:53--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-24 14:42:54--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-24 14:42:54 (47.2 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 57 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 65.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOAIQjXg5Ojb",
        "outputId": "17e33fc5-4886-40e6-a017-3801b7dbce8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-24 14:43:54--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-24 14:43:55--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-24 14:43:55--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘colab.sh’\n",
            "\n",
            "colab.sh            100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-24 14:43:55 (44.2 MB/s) - ‘colab.sh’ saved [1275/1275]\n",
            "\n",
            "#!/bin/bash\n",
            "\n",
            "#default values for pyspark, spark-nlp, and SPARK_HOME\n",
            "SPARKNLP=\"3.3.4\"\n",
            "PYSPARK=\"3.0.3\"\n",
            "\n",
            "while getopts s:p: option\n",
            "do\n",
            " case \"${option}\"\n",
            " in\n",
            " s) SPARKNLP=${OPTARG};;\n",
            " p) PYSPARK=${OPTARG};;\n",
            " esac\n",
            "done\n",
            "\n",
            "echo \"setup Colab for PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
            "\n",
            "if [[ \"$PYSPARK\" == \"3.1\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "elif [[ \"$PYSPARK\" == \"3.0\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "elif [[ \"$PYSPARK\" == \"2\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "  apt-get update\n",
            "  apt-get purge -y openjdk-11* -qq > /dev/null && sudo apt-get autoremove -y -qq > /dev/null\n",
            "  apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
            "\n",
            "  export SPARK_HOME=$SPARKHOME\n",
            "  export JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
            "\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-2.4.8-bin-hadoop2.8.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-2.4.8-bin-hadoop2.7\"\n",
            "else\n",
            "  export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
            "  PYSPARK=\"3.0.3\"\n",
            "fi\n",
            "\n",
            "\n",
            "# Install pyspark spark-nlp\n",
            "! pip install --upgrade -q pyspark==$PYSPARK spark-nlp==$SPARKNLP findspark\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh \n",
        "\n",
        "! cat /content/colab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uCXppdL5Ogk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2.1 spark related\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType, StringType,StructField,StructType\n",
        "#Replace part of string with another string\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "# 2.2 Spark-nlp related\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ublKZRwd5Od0"
      },
      "outputs": [],
      "source": [
        "# 2.3 Create Spark session\n",
        "#     And start sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhBw6HuL5ObW"
      },
      "outputs": [],
      "source": [
        "# 2.4 Show multiple command outputs from a cell\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX4iTp2Z5OY2",
        "outputId": "ee0470c6-4045-4c1c-a2f5-73ff768c1fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n",
            "{'checked': ['Movie', 'was', 'worthless'], 'document': ['Movie was worthless '], 'sentiment': ['negative'], 'token': ['Movie', 'was', 'worthless'], 'sentence': ['Movie was worthless']}\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "pipeline = PretrainedPipeline('analyze_sentiment', lang = 'en')\n",
        "result =  pipeline.annotate(\"Movie was worthless \")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDeLunpq5OWA",
        "outputId": "ae1735fe-f594-4e59-9e66-97cee72d7be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# 2.3 Mount gdrive to read data\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjza4Pi16w4X"
      },
      "outputs": [],
      "source": [
        "# 4.0 Read data directly in spark a normal manner:\n",
        "\n",
        "data = spark.read.csv(\n",
        "                      path = '/gdrive/MyDrive/IMDB Dataset.csv',\n",
        "                      inferSchema=True,\n",
        "                      header=True\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G4NwIzA7dOv",
        "outputId": "df81e5d9-c233-47e6-c79e-c74cb4c41767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|              review|           sentiment|\n",
            "+--------------------+--------------------+\n",
            "|One of the other ...|            positive|\n",
            "|\"A wonderful litt...| not only is it w...|\n",
            "|\"I thought this w...| but spirited you...|\n",
            "|Basically there's...|            negative|\n",
            "+--------------------+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.show(4)\n",
        "data.count() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCqei1vT7lyX",
        "outputId": "f7ec9487-e7b5-4023-eaa0-fa5ed9550ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Row(review=\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\", sentiment='positive')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG7dmP-s8DhA"
      },
      "outputs": [],
      "source": [
        "# 5.0 First define a Spark schema:\n",
        "schema = StructType([ \\\n",
        "                     StructField(\"review\",StringType(),True), \\\n",
        "                     StructField(\"sentiment\",StringType(),True), \\\n",
        "  ])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh2TWmfy8nf8"
      },
      "outputs": [],
      "source": [
        "# 5.1 Next read the data:\n",
        "\n",
        "trainDataset = spark.read  \\\n",
        "                 .option(\"quote\", \"\\\"\") \\\n",
        "                 .option('escape', \"\\\"\") \\\n",
        "                 .option(\"multiLine\", \"true\")  \\\n",
        "                 .option(\"schema\" , schema)  \\\n",
        "                 .option(\"header\", \"true\") \\\n",
        "                 .csv('/gdrive/MyDrive/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEj8U_5L8yJs",
        "outputId": "f7cb3cd4-fcdd-43ae-89c3-138353f6fdcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|              review|sentiment|\n",
            "+--------------------+---------+\n",
            "|One of the other ...| positive|\n",
            "|A wonderful littl...| positive|\n",
            "|I thought this wa...| positive|\n",
            "|Basically there's...| negative|\n",
            "|Petter Mattei's \"...| positive|\n",
            "|Probably my all-t...| positive|\n",
            "|I sure would like...| positive|\n",
            "|This show was an ...| negative|\n",
            "|Encouraged by the...| negative|\n",
            "|If you like origi...| positive|\n",
            "|Phil the Alien is...| negative|\n",
            "|I saw this movie ...| negative|\n",
            "|So im not a big f...| negative|\n",
            "|The cast played S...| negative|\n",
            "|This a fantastic ...| positive|\n",
            "|Kind of drawn in ...| negative|\n",
            "|Some films just s...| positive|\n",
            "|This movie made i...| negative|\n",
            "|I remember this f...| positive|\n",
            "|An awful film! It...| negative|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5.2 The result shows complete match with pandas:\n",
        "trainDataset.show()\n",
        "trainDataset.count() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6tQnwUV81W9",
        "outputId": "9db09461-8507-4766-b406-1181ca8fdbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|sentiment|count|\n",
            "+---------+-----+\n",
            "| positive|25000|\n",
            "| negative|25000|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5.3 Distribution of classes:\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# 5.3.1\n",
        "trainDataset.groupBy(\"sentiment\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjGR_9n189of",
        "outputId": "2975455e-0695-4d7f-c97c-b3a8a4d62e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 40055\n",
            "Test Dataset Count: 9945\n"
          ]
        }
      ],
      "source": [
        "(trainingData, testData) = trainDataset.randomSplit([0.8, 0.2], seed = 100)\n",
        "\n",
        "# 6.0.1\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In9SXutj9Ubd",
        "outputId": "d3b7e1fc-1739-4547-a37d-d563b96bfe04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "#pipelinig for data cleaning\n",
        "# 6.1\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"review\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "# 6.2    \n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# 6.3      \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "# 6.4\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleanTokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "# 6.5\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNjt9AbA-NMy",
        "outputId": "b23b71b5-71e7-4e8d-dee1-8bb9fe629f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# 7.0\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "# 7.1\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "# 7.2\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"sentiment\")\\\n",
        "      .setMaxEpochs(100)\\\n",
        "      .setEnableOutputLogs(True)\n",
        "      #.setOutputLogsPath('logs')\n",
        "\n",
        "# 7.3\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SQyjWKPJ-jsV",
        "outputId": "c74f34ac-0143-4951-bb64-98c224875693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7.87 s, sys: 799 ms, total: 8.67 s\n",
            "Wall time: 22min 48s\n"
          ]
        }
      ],
      "source": [
        "# 8.0 Train \n",
        "%%time\n",
        "\n",
        "clf_pipelineModel = clf_pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szfs1jML-sdA"
      },
      "outputs": [],
      "source": [
        "preds = clf_pipelineModel.transform(testData)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.select('sentiment','review',\"class.result\").show(10, truncate=80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa4_QCmZi6AL",
        "outputId": "6681cb9f-da6d-4771-c93f-d35d06c90751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------------------------------------------------------------------+----------+\n",
            "|sentiment|                                                                          review|    result|\n",
            "+---------+--------------------------------------------------------------------------------+----------+\n",
            "| negative|!!!! MILD SPOILERS !!!!<br /><br />With the exception of THE TERMINATOR and T...|[negative]|\n",
            "| positive|\" Now in India's sunny 'clime, where I use to spend my time as a soldier in t...|[positive]|\n",
            "| positive|\"2001: A Space Odyssey\" is set in 2001 and the main character is HAL. A compu...|[negative]|\n",
            "| negative|\"A Christmas Story\" is one of many people's all-time most beloved films. ACS ...|[negative]|\n",
            "| positive|\"A Fare to Remember\" is a totally derivative, almost ridiculous movie, but ha...|[positive]|\n",
            "| negative|\"A Guy Thing\" tries to capture the feeling of \"There's Something About Mary\" ...|[negative]|\n",
            "| negative|\"A Texas community is beset with a rash of mysterious killings involving some...|[positive]|\n",
            "| positive|\"A Thief in the Night\" is a film that was generally ignored by movie fans at ...|[positive]|\n",
            "| negative|\"A bored television director is introduced to the black arts and astral proje...|[positive]|\n",
            "| negative|\"A death at a college campus appears to be a suicide but is actually a cover ...|[positive]|\n",
            "+---------+--------------------------------------------------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.2\n",
        "\n",
        "preds_df = preds.select('sentiment','review',\"class.result\").toPandas()\n",
        "\n",
        "# The result is an array since in Spark NLP you can have multiple sentences.\n",
        "# Let's explode the array and get the item(s) inside of result column out\n",
        "\n",
        "# 9.3\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
      ],
      "metadata": {
        "id": "iTAkdEy8jJTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.4 We are going to use sklearn to evalute \n",
        "#      the results on test dataset:\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 9.5\n",
        "print (classification_report(preds_df['result'], preds_df['sentiment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JDrCbDjfZT",
        "outputId": "ceece5f6-ccc1-4ee6-aa1c-45a7e6e9e856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.81      0.79      0.80      5067\n",
            "    positive       0.79      0.81      0.80      4878\n",
            "\n",
            "    accuracy                           0.80      9945\n",
            "   macro avg       0.80      0.80      0.80      9945\n",
            "weighted avg       0.80      0.80      0.80      9945\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yavx2MPYjfWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "05AHWyhwjfTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "IMBD Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}